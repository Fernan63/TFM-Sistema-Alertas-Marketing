"""
M√≥dulo principal del sistema de alertas por anomal√≠as.
Implementa los algoritmos STL+MAD e Isolation Forest.
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging

class SistemaAlertasMarketing:
    """Sistema autom√°tico de detecci√≥n de anomal√≠as en m√©tricas de marketing."""
    
    def __init__(self, ventana_analisis=60, umbral_mad=3.2, contaminacion_if=0.01):
        """
        Inicializa el sistema con par√°metros configurables.
        
        Args:
            ventana_analisis (int): D√≠as hist√≥ricos a analizar (default: 60)
            umbral_mad (float): Umbral para detecci√≥n MAD (default: 3.2)
            contaminacion_if (float): Proporci√≥n esperada de anomal√≠as (default: 0.01)
        """
        self.ventana_analisis = ventana_analisis
        self.umbral_mad = umbral_mad
        self.contaminacion_if = contaminacion_if
        self.logger = logging.getLogger(__name__)
        
    def cargar_datos_ejemplo(self):
        """
        Carga datos de ejemplo para demostraci√≥n.
        En producci√≥n, esto se conectar√≠a a las APIs reales.
        """
        self.logger.info("üìÇ Cargando datos de ejemplo...")
        
        # Generar datos sint√©ticos para demostraci√≥n
        fechas = pd.date_range(
            start=datetime.now() - timedelta(days=self.ventana_analisis),
            end=datetime.now(),
            freq='D'
        )
        
        datos = pd.DataFrame({
            'fecha': fechas,
            'sesiones': np.random.poisson(1000, len(fechas)) + 
                       np.sin(np.arange(len(fechas)) * 2 * np.pi / 7) * 200,
            'leads': np.random.poisson(50, len(fechas)) + 
                    np.sin(np.arange(len(fechas)) * 2 * np.pi / 7) * 10,
            'inversion': np.random.normal(800, 100, len(fechas))
        })
        
        # Introducir algunas anomal√≠as para demostraci√≥n
        datos.loc[10, 'sesiones'] = 5000  # Pico artificial
        datos.loc[25, 'leads'] = 5        # Ca√≠da artificial
        datos.loc[40, 'inversion'] = 2000 # Pico artificial
        
        return datos
    
    def detectar_anomalias_stl_mad(self, serie, nombre_metrica):
        """
        Detecta anomal√≠as usando el m√©todo STL + MAD.
        
        Args:
            serie (pd.Series): Serie temporal a analizar
            nombre_metrica (str): Nombre de la m√©trica para logging
            
        Returns:
            list: Lista de diccionarios con anomal√≠as detectadas
        """
        try:
            self.logger.info(f"üîç Aplicando STL+MAD a {nombre_metrica}...")
            
            # Simulaci√≥n de STL - en producci√≥n usar statsmodels
            # stl = STL(serie, period=7, robust=True)
            # result = stl.fit()
            # residuals = result.resid
            
            # Para demostraci√≥n, simulamos residuos
            tendencia = serie.rolling(window=7).mean()
            residuos = serie - tendencia
            
            # Calcular MAD (Median Absolute Deviation)
            mediana = np.median(residuos)
            mad = np.median(np.abs(residuos - mediana))
            
            # Definir umbrales
            umbral_superior = mediana + self.umbral_mad * mad
            umbral_inferior = mediana - self.umbral_mad * mad
            
            # Detectar anomal√≠as
            anomalias = []
            for idx, (fecha, valor, residuo) in enumerate(zip(serie.index, serie.values, residuos)):
                if residuo > umbral_superior or residuo < umbral_inferior:
                    tipo = "pico" if residuo > umbral_superior else "caida"
                    magnitud = abs((valor - mediana) / mediana) * 100
                    
                    anomalias.append({
                        'fecha': fecha,
                        'valor': valor,
                        'tipo': tipo,
                        'metrica': nombre_metrica,
                        'magnitud_relativa': round(magnitud, 2),
                        'metodo': 'STL+MAD',
                        'score_anomalia': abs(residuo) / mad
                    })
            
            self.logger.info(f"‚úÖ STL+MAD detect√≥ {len(anomalias)} anomal√≠as en {nombre_metrica}")
            return anomalias
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en STL+MAD para {nombre_metrica}: {str(e)}")
            return []
    
    def detectar_anomalias_isolation_forest(self, datos):
        """
        Detecta anomal√≠as usando Isolation Forest (simulado).
        
        Args:
            datos (pd.DataFrame): DataFrame con m√∫ltiples m√©tricas
            
        Returns:
            list: Lista de anomal√≠as detectadas
        """
        try:
            self.logger.info("ü§ñ Aplicando Isolation Forest...")
            
            # En producci√≥n se usar√≠a:
            # from sklearn.ensemble import IsolationForest
            # from sklearn.preprocessing import StandardScaler
            
            # Simulaci√≥n simplificada para demostraci√≥n
            metricas = ['sesiones', 'leads', 'inversion']
            datos_limpios = datos[metricas].dropna()
            
            if len(datos_limpios) < 10:
                return []
            
            # Simular scores de anomal√≠a (en producci√≥n ser√≠an reales)
            np.random.seed(42)  # Para reproducibilidad
            scores = np.random.exponential(0.1, len(datos_limpios))
            
            # Introducir algunos scores altos para demostraci√≥n
            scores[10] = 0.9  # Anomal√≠a en √≠ndice 10
            scores[25] = 0.8  # Anomal√≠a en √≠ndice 25
            scores[40] = 0.95 # Anomal√≠a en √≠ndice 40
            
            # Identificar anomal√≠as (percentil 99)
            umbral = np.percentile(scores, 99)
            indices_anomalias = np.where(scores > umbral)[0]
            
            anomalias = []
            for idx in indices_anomalias:
                fecha = datos_limpios.index[idx]
                anomalias.append({
                    'fecha': fecha,
                    'score_anomalia': round(scores[idx], 4),
                    'tipo': 'patron_multivariante',
                    'metricas_afectadas': metricas,
                    'metodo': 'IsolationForest',
                    'valores': datos_limpios.iloc[idx].to_dict()
                })
            
            self.logger.info(f"‚úÖ Isolation Forest detect√≥ {len(anomalias)} anomal√≠as multivariantes")
            return anomalias
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en Isolation Forest: {str(e)}")
            return []
    
    def enviar_alerta_teams(self, alerta):
        """
        Simula el env√≠o de alertas a Microsoft Teams.
        
        Args:
            alerta (dict): Informaci√≥n de la alerta a enviar
        """
        try:
            # En producci√≥n se usar√≠a:
            # import requests
            # webhook_url = "tu_webhook_url"
            # requests.post(webhook_url, json=alerta)
            
            self.logger.info(f"üì§ Alerta Teams: {alerta['tipo']} en {alerta.get('metrica', 'm√∫ltiples')}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error enviando alerta: {str(e)}")
            return False
    
    def ejecutar_pipeline_completo(self):
        """
        Ejecuta el pipeline completo de detecci√≥n de anomal√≠as.
        
        Returns:
            dict: Resultados del procesamiento
        """
        self.logger.info("üöÄ Iniciando pipeline completo...")
        
        # 1. Cargar datos
        datos = self.cargar_datos_ejemplo()
        
        # 2. Detecci√≥n STL+MAD por m√©trica
        alertas_stl = []
        for metrica in ['sesiones', 'leads', 'inversion']:
            serie = datos.set_index('fecha')[metrica]
            alertas_metrica = self.detectar_anomalias_stl_mad(serie, metrica)
            alertas_stl.extend(alertas_metrica)
        
        # 3. Detecci√≥n Isolation Forest
        datos_indexados = datos.set_index('fecha')
        alertas_if = self.detectar_anomalias_isolation_forest(datos_indexados)
        
        # 4. Combinar y enviar alertas
        alertas_totales = alertas_stl + alertas_if
        
        for alerta in alertas_totales:
            self.enviar_alerta_teams(alerta)
        
        # 5. Retornar resultados
        resultados = {
            'total_dominios': 1,  # En producci√≥n ser√≠a el n√∫mero real
            'total_alertas': len(alertas_totales),
            'alertas_stl': len(alertas_stl),
            'alertas_if': len(alertas_if),
            'alertas_faltantes': 0,  # En producci√≥n se calcular√≠a
            'fecha_ejecucion': datetime.now().isoformat()
        }
        
        self.logger.info("üéâ Pipeline completado exitosamente")
        return resultados